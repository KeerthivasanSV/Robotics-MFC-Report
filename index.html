<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta content="" name="description">
    <meta content="" name="author">
    
    <meta name="experiment-short-name" content="pvc-hot-water-coupling">
    <meta name="developer-institute" content="Amrita Vishwa Vidyapeetham">
    <meta name="learning-unit" content="Automated PVC Hot Water Coupling Using AI & Robotics">
    <meta name="task-name" content="Theory">
    
    <title>Automated PVC Hot Water Coupling Using AI & Robotics</title>
    <link rel="shortcut icon" href="./assets/images/favicon.ico">
    <link rel="stylesheet" href="./assets/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/github-markdown-css/4.0.0/github-markdown.min.css">
    <link href="https://fonts.googleapis.com/css2?family=Open+Sans&family=Raleway&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="./assets/fonts/font-awesome-4.7.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="./assets/css/github-markdown.min.css">
    <link rel="stylesheet" href="./assets/css/vlabs-style.css">
    <link rel="stylesheet" href="./assets/css/toast.css">
    <link rel="stylesheet" href="./assets/katex_assets/katex.min.css">
    
    <script src="./assets/js/jquery-3.4.1.slim.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.5.4/dist/umd/popper.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta1/dist/js/bootstrap.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/sweetalert2@11"></script>
    <style>
      /* Blue-based color scheme */
      :root {
        --primary-blue: #1a73e8;
        --secondary-blue: #4285f4;
        --light-blue: #e8f0fe;
        --dark-blue: #174ea6;
        --text-dark: #202124;
      }
      
      body {
        font-family: 'Open Sans', sans-serif;
        color: var(--text-dark);
      }
      
      h1 {
        font-size: 1.8rem;
        color: var(--primary-blue);
        margin-top: 2rem;
      }
      
      h2 {
        font-size: 1.4rem;
        color: var(--dark-blue);
      }
      
      h3 {
        font-size: 1.2rem;
        color: var(--dark-blue);
      }
      
      h2, h3 {
        font-weight: 800;
      }
      
      .navbar {
        background-color: var(--primary-blue) !important;
        color: white !important;
      }
      
      .nav-menu {
        background-color: var(--light-blue);
        border-right: 1px solid #ddd;
      }
      
      .nav-menu-body a {
        color: var(--dark-blue) !important;
        text-decoration: none;
        display: block;
        padding: 0.5rem 1rem;
        margin: 2px 0;
        border-radius: 4px;
        transition: background-color 0.3s;
      }
      
      .nav-menu-body a:hover {
        background-color: rgba(66, 133, 244, 0.1);
        font-weight: bold;
      }
      
      .vlabs-footer {
        background-color: var(--dark-blue) !important;
      }
      
      .code-block {
        background: #f8f9fa;
        padding: 10px 15px;
        border-radius: 4px;
        font-family: monospace;
        overflow-x: auto;
        margin-bottom: 20px;
        border-left: 4px solid var(--primary-blue);
      }
      
      .equation {
        padding: 10px;
        margin: 10px 0;
        background: #f9f9f9;
        border-left: 4px solid var(--primary-blue);
        text-align: center;
      }
      
      /* Add this new CSS for equations */
      .equation p {
        margin-bottom: 0.5rem;
      }
      
      .equation p:last-child {
        margin-bottom: 0;
      }
      
      /* Improve MathJax rendering */
      .MathJax {
        overflow-x: auto;
        overflow-y: hidden;
        max-width: 100%;
      }
      
      .team-member {
        margin-bottom: 15px;
      }
      
      .method-section {
        margin-bottom: 30px;
      }
      
      .algorithm-box {
        border: 1px solid #e0e0e0;
        padding: 15px;
        border-radius: 8px;
        margin-bottom: 20px;
        background-color: #f8f9fa;
        border-left: 4px solid var(--primary-blue);
      }
      
      .algorithm-box h4 {
        color: var(--primary-blue);
        margin-top: 0;
      }
      
      .feature-list {
        list-style-type: none;
        padding-left: 0;
      }
      
      .feature-list li {
        padding: 5px 0;
        padding-left: 25px;
        position: relative;
      }
      
      .feature-list li:before {
        content: "🔹";
        position: absolute;
        left: 0;
        color: var(--primary-blue);
      }
      
      .implementation-step {
        padding: 10px;
        margin-bottom: 15px;
        border-bottom: 1px solid #eee;
      }
      
      .data-flow-diagram {
        width: 100%;
        max-width: 600px;
        margin: 20px auto;
        border: 1px solid #ddd;
        padding: 10px;
      }
      
      .literature-table {
        width: 100%;
        border-collapse: collapse;
        margin: 20px 0;
      }
      
      .literature-table th, .literature-table td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;
      }
      
      .literature-table th {
        background-color: var(--light-blue);
        color: var(--dark-blue);
      }
      
      /* New left navigation styling */
      .sidebar-nav {
        position: sticky;
        top: 0;
        background: var(--light-blue);
        border-right: 1px solid #ddd;
        height: 100vh;
        overflow-y: auto;
        padding: 1rem 0;
      }
      
      .chapter-link {
        display: block;
        padding: 0.5rem 1rem;
        color: var(--dark-blue);
        text-decoration: none;
        border-left: 4px solid transparent;
        transition: all 0.2s;
      }
      
      .chapter-link:hover, .chapter-link:focus {
        background-color: rgba(66, 133, 244, 0.1);
        border-left-color: var(--primary-blue);
        font-weight: bold;
      }
      
      .page-title {
        color: var(--primary-blue);
        padding: 1rem;
        font-weight: bold;
        font-size: 1.1rem;
      }
      
      .course-info {
        color: var(--dark-blue);
        font-size: 0.9rem;
        padding: 0 1rem 1rem;
        margin-bottom: 1rem;
        border-bottom: 1px solid #ddd;
      }
    </style>
</head>

<body class="p-0 container-fluid vlabs-page d-flex flex-column justify-content-between">
    <header class="vlabs-header sticky-top bg-white">
        <nav class="p-0 navbar navbar-light d-flex align-items-stretch" style="background-color: #1a73e8 !important;">
            <div class="d-flex justify-content-center w-100 align-items-center p-3">
                <span class="text-white font-weight-bold">Automated PVC Hot Water Coupling Using AI & Robotics</span>
            </div>
        </nav>
    </header>

    <div class="container-fluid flex-fill d-flex flex-column vlabs-page-main">
        <div class="row flex-grow-1 d-flex flex-nowrap flex-column flex-lg-row">
            <div class="col-lg-3 col-xl-2 sidebar-nav d-none d-lg-block" id="menu">
                <div class="page-title">MFC ROBOTICS - Group 9</div>
                <div class="course-info">
                    22MAT230: Mathematics for Computing<br>
                    22AlE214: Introduction to Al & Robotics
                </div>
                
                <a href="#introduction" class="chapter-link">1. Introduction</a>
                <a href="#problem-statement" class="chapter-link">2. Problem Statement</a>
                <a href="#proposed-solution" class="chapter-link">3. Proposed Solution</a>
                <a href="#methodology-and-implementation" class="chapter-link">4. Methodology, AI Algorithms & Mathematical Foundations (YOLO, Adaptive Gripping, Min-Jerk, HIK)</a>
                <a href="#technical-implementation" class="chapter-link">5. Technical Implementation & Algorithm Code (YOLO Detection, Force Optimization, HIK Solver, Min-Jerk Planner)</a>
                <a href="#progress-and-challenges" class="chapter-link">6. Progress and Challenges</a>
                <a href="#literature-review" class="chapter-link">7. Literature Review</a>
                <a href="#experimental-results" class="chapter-link">8. Experimental Results</a>
                <a href="#conclusion" class="chapter-link">9. Conclusion</a>
                <a href="#acknowledgments" class="chapter-link">10. Acknowledgments</a>
                <a href="#references" class="chapter-link">11. References</a>
                <a href="model.html" class="chapter-link">12. Robot Model Demo</a>
                <a href="simulation.html" class="chapter-link">13. RoboDK Simulation</a>
                <a href="gripper.html" class="chapter-link">14. 3-Finger Adaptive Gripper</a>
                <a href="qanda.html" class="chapter-link">15. Q&A Section</a>
            </div>

            <div class="col-lg-9 col-xl-10 vlabs-page-content px-5 pb-4 flex-grow-1 markdown-body">
                <div class="text-center fix-spacing">
                    <h2 id="automated-pvc-hot-water-coupling">Automated PVC Hot Water Coupling Using AI & Robotics</h2>
                    <h3 id="an-innovative-approach">An Innovative Approach to Industrial Automation</h3>
                </div>

                <div class="team-member">
                    <h3>Group 9 - MFC ROBOTICS (February 7, 2025)</h3>
                    <ol>
                        <li>Abhishek Karthik J - CB.SC.U4AIE23010</li>
                        <li>Keerthivasan S V - CB.SC.U4AIE23037</li>
                        <li>Mothishwaran M P - CB.SC.U4AIE23041</li>
                        <li>Mopuru Sai Bavesh Reddy - CB.SC.U4AIE23044</li>
                    </ol>
                </div>

                <h1 id="introduction">1. Introduction</h1>
                <p>The PVC hot water coupling process traditionally requires manual labor with several critical steps. This labor-intensive process, while effective for small-scale operations, presents numerous challenges in industrial settings where consistency, efficiency, and safety are paramount concerns.</p>
                
                <div class="method-section">
                    <h3>1.1 Current Manual Process</h3>
                    <p>The conventional PVC hot water coupling process involves the following manual steps:</p>
                    <ul>
                        <li><strong>Step 1:</strong> Dipping PVC pipes into hot water mixed with calcium chloride to soften the material.</li>
                        <li><strong>Step 2:</strong> Precisely placing the softened pipe into a mold while maintaining proper alignment.</li>
                        <li><strong>Step 3:</strong> Applying consistent pressure to ensure proper shaping of the coupling.</li>
                        <li><strong>Step 4:</strong> Cooling the formed coupling and releasing the final product.</li>
                    </ul>
                    <p>This manual process is highly dependent on worker skill and consistency, making it susceptible to various inefficiencies and quality issues.</p>
                </div>

                <div class="method-section">
                    <h3>1.2 Challenges in the Manual Process</h3>
                    <p>The traditional method faces several significant challenges that impact production quality, efficiency, and worker safety:</p>
                    <ul>
                        <li><strong>Inconsistent Quality:</strong> Manual handling leads to variations in dipping time, placement accuracy, and applied pressure.</li>
                        <li><strong>Labor Intensity:</strong> The process requires continuous human involvement, leading to fatigue and reduced productivity.</li>
                        <li><strong>Scalability Limitations:</strong> Scaling production requires proportional increases in skilled labor.</li>
                        <li><strong>Safety Concerns:</strong> Workers are exposed to hot water and chemicals, posing significant workplace hazards.</li>
                        <li><strong>Efficiency Bottlenecks:</strong> The manual process creates bottlenecks in production pipelines, limiting overall manufacturing output.</li>
                    </ul>
                </div>

                <h1 id="problem-statement">2. Problem Statement</h1>
                <div class="method-section">
                    <h3>2.1 Labour-Intensive & Inconsistent</h3>
                    <p>The current process relies heavily on manual labor, resulting in variable product quality and efficiency. Human operators must continuously monitor and adjust the process, which introduces inconsistencies in the final product. These variations can lead to coupling failures, leaks, and reduced product lifespan.</p>
                    
                    <h3>2.2 Limitations of Existing Automation Solutions</h3>
                    <p>Current automation solutions in the market still require significant human intervention. Most systems can only automate portions of the process, requiring operators to:
                    <ul>
                        <li>Manually position and align pipes for pickup</li>
                        <li>Monitor heating duration and temperature</li>
                        <li>Supervise the molding process for alignment issues</li>
                        <li>Manually adjust for different pipe sizes</li>
                    </ul>
                    <p>These semi-automated approaches fail to address the fundamental need for a fully autonomous system capable of handling the complete process cycle.</p>
                    
                    <h3>2.3 Specific Challenges Requiring Solution</h3>
                    <ul>
                        <li><strong>Fatigue & Errors:</strong> Human involvement increases the risk of errors and inconsistencies, especially during extended production runs.</li>
                        <li><strong>Limited Scalability:</strong> Current methods are difficult to scale for high-volume production requirements.</li>
                        <li><strong>Safety Hazards:</strong> Handling hot materials poses significant risks to workers, including burns and exposure to chemicals.</li>
                        <li><strong>Inefficient Resource Utilization:</strong> Manual and semi-automated processes require more floor space, energy, and materials due to inconsistent processing.</li>
                        <li><strong>Quality Control Challenges:</strong> Variations in the manual process make consistent quality control difficult to implement and maintain.</li>
                    </ul>
                </div>

                <h1 id="proposed-solution">3. Proposed Solution</h1>
                <div class="method-section">
                    <h3>3.1 A Fully Automated System</h3>
                    <p>We propose a comprehensive automation solution that integrates advanced robotics, computer vision, and adaptive force control to create a fully autonomous PVC hot water coupling system. This end-to-end solution eliminates the need for human intervention throughout the entire process.</p>
                    
                    <h3>3.2 Core Benefits</h3>
                    <ul>
                        <li><strong>Elimination of Human Dependency:</strong> The system operates without human supervision, reducing labor costs and eliminating fatigue-related quality issues.</li>
                        <li><strong>Enhanced Accuracy and Precision:</strong> Robotic control ensures consistent force application and precise placement for every pipe, resulting in uniform product quality.</li>
                        <li><strong>Improved Scalability:</strong> The autonomous system can be easily scaled by adding additional units, allowing for flexible production capacity adjustment.</li>
                        <li><strong>Adaptability for Different Sizes:</strong> The system dynamically adjusts to different pipe and coupler dimensions without requiring manual reconfiguration.</li>
                        <li><strong>Increased Safety:</strong> By removing humans from direct interaction with hot materials and chemicals, workplace safety is significantly improved.</li>
                    </ul>
                    
                    <h3>3.3 Core Objectives</h3>
                    <ol>
                        <li><strong>Full Automation:</strong> Eliminate manual labor throughout the entire PVC coupling process, from pipe detection to final product delivery.</li>
                        <li><strong>Precision Maximization:</strong> Implement advanced algorithms to ensure accurate picking, heating, and placement with sub-millimeter precision.</li>
                        <li><strong>Dynamic Adaptability:</strong> Create a system capable of adjusting to varying pipe and mold dimensions without manual reconfiguration.</li>
                        <li><strong>Novel Technology Integration:</strong> Incorporate cutting-edge solutions including YOLOv8-based pipe detection, adaptive force-optimized gripping, and hierarchical inverse kinematics for precision placement.</li>
                    </ol>
                </div>

                <h1 id="methodology-and-implementation">4. Methodology, Implementation, and Mathematical Foundations</h1>
                <div class="method-section">
                    <h3>4.1 Overview</h3>
                    <p>Our approach integrates advanced robotics, computer vision, and mathematical modeling to create a fully automated PVC hot water coupling system. This comprehensive methodology combines theoretical foundations with practical implementation to address the challenges of pipe detection, adaptive gripping, and precision placement.</p>
                    
                    <h3>4.2 Flat Surface Layout Approach</h3>
                    <p>Our system utilizes a flat surface layout that simplifies the automation process:</p>
                    <div class="algorithm-box">
                        <h4>Key Advantages of Flat Surface Design:</h4>
                        <ul>
                            <li><strong>Enhanced Object Detection:</strong> YOLOv8 can identify pipes more effectively when placed on a flat plane due to consistent lighting and reduced occlusion.</li>
                            <li><strong>Simplified Grasping Mechanics:</strong> A three-fingered adaptive gripper can reliably secure pipes from above, eliminating complex side-grasping requirements.</li>
                            <li><strong>Uniform Robotic Movement:</strong> The robotic arm maintains consistent movement patterns, reducing the complexity of path planning and control algorithms.</li>
                        </ul>
                    </div>
                    
                    <h3>4.3 Robotic Arm Design & Motion Planning</h3>
                    <p>We've designed a specialized robotic arm optimized for the PVC coupling process with the following key features:</p>
                    
                    <h4>4.3.1 Degrees of Freedom (DOF)</h4>
                    <ul>
                        <li><strong>4-DOF Design:</strong> While our robot has 6-DOF capabilities, we utilize 4 DOF for effective control of the PVC coupling process.</li>
                        <li><strong>Fixed Downward-Facing End Effector:</strong> This configuration ensures consistent picking and placement operations without requiring complex orientation adjustments.</li>
                    </ul>
                    
                    <h4>4.3.2 Vision System for Pipe Detection</h4>
                    <ul>
                        <li><strong>Centrally Mounted Camera:</strong> A high-resolution camera mounted at the center of the end effector provides a real-time view of pipes and molds.</li>
                        <li><strong>YOLOv8 Integration:</strong> The advanced object detection model identifies pipes and outputs precise location data in real-world coordinates.</li>
                    </ul>
                    
                    <h4>4.3.3 Gripper Mechanism</h4>
                    <ul>
                        <li><strong>Three-Fingered Adaptive Design:</strong> The gripper applies mathematically optimized force to securely hold pipes without slippage or deformation.</li>
                        <li><strong>Variable Diameter Accommodation:</strong> The system automatically adjusts to pipes of different sizes without manual reconfiguration.</li>
                    </ul>
                    
                    <h3>4.4 YOLOv8 Object Detection for PVC Pipe Recognition</h3>
                    
                    <h4>4.4.1 YOLO Architecture: You Only Look Once</h4>
                    <p>YOLOv8 (You Only Look Once) is a state-of-the-art object detection algorithm that processes the entire image in a single pass, making it well-suited for real-time applications like our robotic system. The core innovation is treating detection as a regression problem:</p>

                    <div class="equation">
                        <p>YOLO divides the image into an S×S grid and for each grid cell predicts:</p>
                        <p>$$P(Object) \cdot IOU_{pred}^{truth}$$</p>
                    </div>

                    <p>Where:</p>
                    <ul>
                        <li>P(Object) is the probability of an object being present</li>
                        <li>IOU (Intersection Over Union) measures prediction accuracy</li>
                    </ul>

                    <div class="data-flow-diagram">
                        <img src="./assets/images/yolo_architecture.png" alt="YOLO architecture showing grid-based detection approach" style="width: 85%;">
                        <p><em>Figure 4.1: YOLO's grid-based approach for simultaneous object detection and classification</em></p>
                    </div>

                    <h4>4.4.2 Loss Function: Multi-Part Optimization</h4>
                    <p>YOLOv8 uses a composite loss function that optimizes for accurate localization, classification, and confidence:</p>

                    <div class="equation">
                        <p>$$L = \lambda_{coord}\sum_{i=0}^{S^2} \sum_{j=0}^B \mathbb{1}_{ij}^{obj} [(x_i - \hat{x}_i)^2 + (y_i - \hat{y}_i)^2] + \lambda_{class}\sum_{i=0}^{S^2} \mathbb{1}_i^{obj} \sum_{c \in classes} (p_i(c) - \hat{p}_i(c))^2$$</p>
                    </div>

                    <p>Where:</p>
                    <ul>
                        <li>$\lambda_{coord}$ weights the importance of localization accuracy</li>
                        <li>$\lambda_{class}$ weights the importance of classification accuracy</li>
                        <li>$\mathbb{1}_{ij}^{obj}$ is 1 if an object appears in cell i and box j</li>
                    </ul>

                    <h4>4.4.3 Implementation: Fine-Tuned Model for PVC Pipe Detection</h4>
                    <p>We implement YOLOv8 specifically optimized for PVC pipe detection in industrial environments:</p>

                    <div class="algorithm-box">
                        <h4>Implementation Features:</h4>
                        <ul class="feature-list">
                            <li>Transfer learning from pre-trained weights for efficient adaptation</li>
                            <li>Fine-tuning with a custom dataset of 2,500 annotated PVC pipe images</li>
                            <li>Data augmentation to improve robustness across lighting conditions</li>
                            <li>Non-maximum suppression for precise bounding box selection</li>
                            <li>Real-time detection capabilities (>30 FPS on industrial hardware)</li>
                        </ul>
                        
                        <div class="implementation-step">
                            <h4>Step 1: Loading and Preparing the Model</h4>
                            <div class="code-block">
<pre>import torch
from ultralytics import YOLO

# Load a pre-trained YOLOv8 model
model = YOLO('yolov8n.pt')

# Fine-tune the model on our custom PVC pipe dataset
results = model.train(
    data='pvc_pipe_dataset.yaml',
    epochs=100,
    imgsz=640,
    batch=16,
    device=0  # Use GPU for training
)</pre>
                            </div>
                        </div>
                        
                        <div class="implementation-step">
                            <h4>Step 2: Detection Pipeline for Robotics Integration</h4>
                            <div class="code-block">
<pre>import cv2

def detect_pvc_pipes(frame):
    """
    Detect PVC pipes in the input frame using our fine-tuned YOLOv8 model.
    
    Args:
        frame: Input image frame from the robot's camera
        
    Returns:
        List of detected pipe bounding boxes in format [x_min, y_min, x_max, y_max, confidence]
    """
    # Run YOLOv8 inference on the frame
    results = model(frame)
    
    # Process the results to extract pipe detections
    detections = []
    for result in results:
        boxes = result.boxes
        for box in boxes:
            # Filter by class (0 = PVC pipe in our model) and confidence
            if box.cls == 0 and box.conf > 0.7:
                x_min, y_min, x_max, y_max = box.xyxy[0].tolist()
                confidence = box.conf.item()
                detections.append([x_min, y_min, x_max, y_max, confidence])
    
    return detections</pre>
                            </div>
                        </div>
                        
                        <div class="implementation-step">
                            <h4>Step 3: 2D to 3D Coordinate Conversion</h4>
                            <div class="code-block">
<pre>import numpy as np

def convert_2d_to_3d(detections, camera_matrix, depth_map=None):
    """
    Convert 2D bounding box detections to 3D world coordinates.
    
    Args:
        detections: List of [x_min, y_min, x_max, y_max, confidence]
        camera_matrix: 3x3 camera intrinsic matrix
        depth_map: Optional depth map from stereo vision or depth sensor
        
    Returns:
        List of pipe centers in 3D coordinates [x, y, z, diameter]
    """
    pipe_3d_coords = []
    
    # Extract camera parameters
    fx = camera_matrix[0, 0]
    fy = camera_matrix[1, 1]
    cx = camera_matrix[0, 2]
    cy = camera_matrix[1, 2]
    
    for detection in detections:
        x_min, y_min, x_max, y_max, conf = detection
        
        # Calculate center of the bounding box
        center_x = (x_min + x_max) / 2
        center_y = (y_min + y_max) / 2
        
        # Estimate pipe diameter in pixels
        diameter_pixels = max(x_max - x_min, y_max - y_min)
        
        # Get depth at the center point (either from depth map or using default)
        if depth_map is not None:
            depth = depth_map[int(center_y), int(center_x)]
        else:
            # Fallback to estimation based on known pipe diameter
            depth = 500  # mm
        
        # Convert from image to world coordinates
        x = (center_x - cx) * depth / fx
        y = (center_y - cy) * depth / fy
        z = depth
        
        # Estimate actual pipe diameter in mm
        diameter_mm = diameter_pixels * depth / fx
        
        pipe_3d_coords.append([x, y, z, diameter_mm])
    
    return pipe_3d_coords</pre>
                            </div>
                        </div>
                    </div>

                    <h3>4.5 Adaptive Force-Optimized Gripping Algorithm</h3>

                    <h4>4.5.1 Force Optimization Problem Formulation</h4>
                    <p>The adaptive gripping algorithm applies optimal force to secure PVC pipes without deformation by formulating a constrained optimization problem:</p>

                    <div class="equation">
                        <p>Minimize the maximum applied force while ensuring stability:</p>
                        <p>$$\min \max |f_i|$$</p>
                    </div>

                    <p>Subject to three key constraints:</p>
                    <ul>
                        <li>Force balance: The gripping forces must counteract external forces like gravity</li>
                        <li>Friction constraints: Prevent slippage between the gripper and pipe</li>
                        <li>Torque limits: Protect the robot joints from excessive strain</li>
                    </ul>

                    <div class="data-flow-diagram">
                        <img src="./assets/images/force_optimization.png" alt="Force optimization diagram showing friction cone constraints" style="width: 85%;">
                        <p><em>Figure 4.2: Force optimization with friction cone constraints ensuring stable grasping</em></p>
                    </div>

                    <h4>4.5.2 Mathematical Constraints</h4>
                    <p>The optimization is governed by three mathematical constraints:</p>

                    <div class="equation">
                        <p><strong>1. Force Balance:</strong> $$G F = -W_{ext}$$</p>
                        <p><strong>2. Friction Cone:</strong> $$\sqrt{f_x^2 + f_y^2} \leq \mu f_z$$</p>
                        <p><strong>3. Torque Constraint:</strong> $$\tau_{min} \leq J^T F \leq \tau_{max}$$</p>
                    </div>

                    <p>Where:</p>
                    <ul>
                        <li>$G$ is the grasp matrix mapping contact forces to object wrenches</li>
                        <li>$F$ is the vector of contact forces</li>
                        <li>$W_{ext}$ represents external forces (primarily gravity)</li>
                        <li>$\mu$ is the friction coefficient between gripper and PVC</li>
                        <li>$J^T$ is the transpose of the robot Jacobian</li>
                    </ul>

                    <h4>4.5.3 Implementation: SLSQP Optimization</h4>
                    <p>We implement this optimization using Sequential Least Squares Quadratic Programming (SLSQP):</p>

                    <div class="algorithm-box">
                        <h4>Implementation Features:</h4>
                        <ul class="feature-list">
                            <li>Force optimization via Sequential Least Squares Programming</li>
                            <li>Adaptive response to different pipe diameters</li>
                            <li>Friction cone constraints to prevent slipping</li>
                            <li>Torque limits to prevent joint overload</li>
                            <li>Mathematical force balance for stable gripping</li>
                        </ul>
                        
                        <div class="implementation-step">
                            <h4>Step 1: Define Optimization Problem</h4>
                            <div class="code-block">
<pre>import numpy as np
from scipy.optimize import minimize

class AdaptiveGripForceOptimizer:
    def __init__(self, mu=0.5, ext_force=10, torque_limit=5):
        """
        Initialize the gripper force optimizer.
        
        Args:
            mu: Friction coefficient between gripper and PVC pipe
            ext_force: External force (primarily gravity) in Newtons
            torque_limit: Maximum allowable joint torque in Nm
        """
        self.mu = mu
        self.ext_force = ext_force
        self.torque_limit = torque_limit
        self.p = 0.1  # Distance from center to contact point in meters
        
    def objective(self, F):
        """Minimize the maximum applied force."""
        return max(abs(F))</pre>
                            </div>
                        </div>
                        
                        <div class="implementation-step">
                            <h4>Step 2: Define Optimization Constraints</h4>
                            <div class="code-block">
<pre>    def force_balance(self, F):
        """Force balance constraint: normal forces must balance external force."""
        return F[2] + F[5] - self.ext_force
        
    def friction_cone_1(self, F):
        """Friction cone constraint for first contact point."""
        return self.mu * F[2] - np.sqrt(F[0]**2 + F[1]**2)
        
    def friction_cone_2(self, F):
        """Friction cone constraint for second contact point."""
        return self.mu * F[5] - np.sqrt(F[3]**2 + F[4]**2)
        
    def torque_limit_1(self, F):
        """Torque limit constraint for first finger."""
        return self.torque_limit - abs(self.p * F[0])
        
    def torque_limit_2(self, F):
        """Torque limit constraint for second finger."""
        return self.torque_limit - abs(self.p * F[3])</pre>
                            </div>
                        </div>
                        
                        <div class="implementation-step">
                            <h4>Step 3: Solve Optimization Problem</h4>
                            <div class="code-block">
<pre>    def optimize(self, pipe_diameter=None):
        """
        Optimize gripping forces for the given pipe diameter.
        
        Args:
            pipe_diameter: Diameter of the pipe in mm (optional)
            
        Returns:
            Optimized forces for each contact point
        """
        # Adjust external force based on pipe diameter if provided
        if pipe_diameter is not None:
            # Calculate pipe mass based on diameter (simplified calculation)
            pipe_volume = np.pi * (pipe_diameter/2000)**2 * 0.1  # 10cm length
            pipe_density = 1400  # kg/m³ for PVC
            pipe_mass = pipe_volume * pipe_density
            self.ext_force = pipe_mass * 9.81  # Force in Newtons
        
        # Define constraints for SLSQP optimization
        constraints = [
            {'type': 'eq', 'fun': self.force_balance},
            {'type': 'ineq', 'fun': self.friction_cone_1},
            {'type': 'ineq', 'fun': self.friction_cone_2},
            {'type': 'ineq', 'fun': self.torque_limit_1},
            {'type': 'ineq', 'fun': self.torque_limit_2}
        ]
        
        # Initial guess for forces [f_x1, f_y1, f_z1, f_x2, f_y2, f_z2]
        initial_guess = [1, 1, self.ext_force/2, 1, 1, self.ext_force/2]
        
        # Solve optimization using SLSQP
        result = minimize(self.objective, initial_guess, method='SLSQP', 
                         constraints=constraints)
                         
        return result.x</pre>
                            </div>
                        </div>
                    </div>

                    <h3>4.6 Minimum-Jerk Trajectory Planning Algorithm</h3>

                    <h4>4.6.1 The Principle of Jerk Minimization</h4>
                    <p>Minimum-jerk trajectory planning creates smooth, natural robot movements by minimizing the third derivative of position (jerk). This approach reduces mechanical stress and vibration while producing human-like motion:</p>

                    <div class="equation">
                        <p>The objective is to minimize the following cost function:</p>
                        <p>$$J = \frac{1}{2} \int_{0}^{T} \left( \frac{d^3x}{dt^3} \right)^2 dt$$</p>
                    </div>

                    <p>Where:</p>
                    <ul>
                        <li>$J$ is the cost function to be minimized</li>
                        <li>$T$ is the total movement duration</li>
                        <li>$\frac{d^3x}{dt^3}$ is the jerk (third derivative of position)</li>
                    </ul>

                    <div class="data-flow-diagram">
                        <img src="./assets/images/min_jerk_profile.png" alt="Minimum-jerk trajectory profile showing smooth position, velocity, and acceleration curves" style="width: 85%;">
                        <p><em>Figure 4.3: Minimum-jerk trajectory profile showing smooth position, velocity, and acceleration curves</em></p>
                    </div>

                    <h4>4.6.2 The 5th-Order Polynomial Solution</h4>
                    <p>The analytical solution to the minimum-jerk problem is a 5th-order polynomial:</p>

                    <div class="equation">
                        <p>$$x(t) = x_0 + (x_f - x_0) \left[ 10\left(\frac{t}{T}\right)^3 - 15\left(\frac{t}{T}\right)^4 + 6\left(\frac{t}{T}\right)^5 \right]$$</p>
                    </div>

                    <p>This polynomial satisfies six crucial boundary conditions:</p>
                    <ul>
                        <li>Initial position: $x(0) = x_0$</li>
                        <li>Final position: $x(T) = x_f$</li>
                        <li>Initial velocity: $\dot{x}(0) = 0$</li>
                        <li>Final velocity: $\dot{x}(T) = 0$</li>
                        <li>Initial acceleration: $\ddot{x}(0) = 0$</li>
                        <li>Final acceleration: $\ddot{x}(T) = 0$</li>
                    </ul>

                    <h4>4.6.3 Implementation: Multi-Waypoint Trajectory Generator</h4>
                    <p>We implement a minimum-jerk trajectory generator that handles multiple waypoints for the PVC coupling process:</p>

                    <div class="algorithm-box">
                        <h4>Implementation Features:</h4>
                        <ul class="feature-list">
                            <li>5th-order polynomial trajectory generation</li>
                            <li>Zero velocity and acceleration at trajectory endpoints</li>
                            <li>Multi-waypoint path planning through critical process points</li>
                            <li>Minimized jerk for reduced mechanical stress and vibration</li>
                            <li>3D trajectory optimization for all axes</li>
                        </ul>
                        
                        <div class="implementation-step">
                            <h4>Step 1: Minimum-Jerk Trajectory Generator</h4>
                            <div class="code-block">
<pre>import numpy as np

class MinimumJerkTrajectoryPlanner:
    """Generate smooth robot trajectories using minimum-jerk optimization."""
    
    def generate_trajectory(self, x0, xf, duration, num_points=100):
        """
        Generate a minimum-jerk trajectory between start and end positions.
        
        Args:
            x0: Starting position as [x, y, z]
            xf: Ending position as [x, y, z]
            duration: Time to complete the movement in seconds
            num_points: Number of points in the trajectory
            
        Returns:
            Dictionary containing positions, velocities, accelerations,
            and jerks for each time point
        """
        # Create time vector
        t = np.linspace(0, duration, num_points)
        
        # Initialize arrays for trajectory data
        positions = np.zeros((num_points, 3))
        velocities = np.zeros((num_points, 3))
        accelerations = np.zeros((num_points, 3))
        jerks = np.zeros((num_points, 3))
        
        # For each dimension (x, y, z)
        for i in range(3):
            # Get the normalized time vector
            tau = t / duration
            
            # Apply minimum jerk formula
            positions[:, i] = x0[i] + (xf[i] - x0[i]) * (10*tau**3 - 15*tau**4 + 6*tau**5)
            
            # Calculate derivatives
            v_scale = (xf[i] - x0[i]) / duration
            velocities[:, i] = v_scale * (30*tau**2 - 60*tau**3 + 30*tau**4)
            
            a_scale = (xf[i] - x0[i]) / (duration**2)
            accelerations[:, i] = a_scale * (60*tau - 180*tau**2 + 120*tau**3)
            
            j_scale = (xf[i] - x0[i]) / (duration**3)
            jerks[:, i] = j_scale * (60 - 360*tau + 360*tau**2)
        
        return {
            'time': t,
            'position': positions,
            'velocity': velocities,
            'acceleration': accelerations,
            'jerk': jerks
        }</pre>
                            </div>
                        </div>
                        
                        <div class="implementation-step">
                            <h4>Step 2: Multi-Waypoint Trajectory Composition</h4>
                            <div class="code-block">
<pre>    def generate_multi_waypoint_trajectory(self, waypoints, durations):
        """
        Generate a trajectory that passes through multiple waypoints.
        
        Args:
            waypoints: List of positions [[x1,y1,z1], [x2,y2,z2], ...]
            durations: List of durations for each segment
            
        Returns:
            Combined trajectory through all waypoints
        """
        if len(waypoints) < 2:
            raise ValueError("At least 2 waypoints required")
            
        if len(waypoints) != len(durations) + 1:
            raise ValueError("Number of durations must be one less than number of waypoints")
            
        # Convert lists to numpy arrays for consistency
        waypoints = np.array(waypoints)
        durations = np.array(durations)
        
        # Generate segment trajectories
        segment_trajectories = []
        for i in range(len(waypoints) - 1):
            start_pos = waypoints[i]
            end_pos = waypoints[i+1]
            duration = durations[i]
            
            trajectory = self.generate_trajectory(start_pos, end_pos, duration)
            segment_trajectories.append(trajectory)
            
        # Concatenate segment trajectories
        total_points = sum(len(traj['time']) for traj in segment_trajectories)
        combined_time = np.zeros(total_points)
        combined_position = np.zeros((total_points, 3))
        combined_velocity = np.zeros((total_points, 3))
        combined_acceleration = np.zeros((total_points, 3))
        
        # Fill in the combined trajectory
        idx = 0
        time_offset = 0
        for traj in segment_trajectories:
            n_points = len(traj['time'])
            combined_time[idx:idx+n_points] = traj['time'] + time_offset
            combined_position[idx:idx+n_points] = traj['position']
            combined_velocity[idx:idx+n_points] = traj['velocity']
            combined_acceleration[idx:idx+n_points] = traj['acceleration']
            
            idx += n_points
            time_offset += traj['time'][-1]
            
        return {
            'time': combined_time,
            'position': combined_position,
            'velocity': combined_velocity,
            'acceleration': combined_acceleration
        }</pre>
                            </div>
                        </div>
                        
                        <div class="implementation-step">
                            <h4>Step 3: PVC Pipe Handling Trajectory</h4>
                            <div class="code-block">
<pre>    def plan_pvc_coupling_path(self, pickup_pos, water_bath_pos, mold_pos, home_pos):
        """
        Plan a complete path for the PVC coupling process:
        1. Pickup position → Water bath
        2. Water bath → Mold position
        3. Mold position → Home position
        
        Args:
            pickup_pos: Position to pick up the PVC pipe [x,y,z]
            water_bath_pos: Position of the water bath [x,y,z]
            mold_pos: Position of the mold for placement [x,y,z]
            home_pos: Home position of the robot [x,y,z]
            
        Returns:
            Complete trajectory for the entire process
        """
        # Define waypoints
        waypoints = [
            pickup_pos,
            water_bath_pos,
            mold_pos,
            home_pos
        ]
        
        # Define appropriate durations for each segment
        durations = [
            3.0,  # Pickup to water bath (slower for careful pickup)
            2.0,  # Water bath to mold (faster while pipe is heated)
            3.0   # Mold to home (medium speed)
        ]
        
        return self.generate_multi_waypoint_trajectory(waypoints, durations)</pre>
                            </div>
                        </div>
                    </div>
                    
                    <h3>4.7 Hierarchical Inverse Kinematics with Nullspace Projection</h3>
                    
                    <h4>4.7.1 Forward Kinematics: The Foundation</h4>
                    <p>Before understanding inverse kinematics, we need to grasp forward kinematics: how joint angles determine the end-effector position.</p>

                    <p>For our robotic arm, the end-effector position (𝐱) is related to joint angles (𝛉) by the forward kinematics function:</p>

                    <div class="equation">
                        <p>$$\mathbf{x} = f(\boldsymbol{\theta})$$</p>
                    </div>

                    <p>This nonlinear function maps configurations in joint space to positions in task space.</p>

                    <h4>4.7.2 The Jacobian Matrix: Relating Velocities</h4>
                    <p>The Jacobian matrix (J) linearizes the relationship between joint velocities and end-effector velocities:</p>

                    <div class="equation">
                        <p>$$\Delta \mathbf{x} = \mathbf{J} \Delta \boldsymbol{\theta}$$</p>
                    </div>

                    <p>Where:</p>
                    <ul>
                        <li>∆𝐱 is the desired change in end-effector position</li>
                        <li>∆𝛉 is the required change in joint angles</li>
                        <li>J is the Jacobian matrix (m×n for m task dimensions and n joints)</li>
                    </ul>

                    <h4>4.7.3 Basic Inverse Kinematics Problem</h4>
                    <p>Inverse kinematics finds joint angles to reach a desired position. Ideally, we want:</p>

                    <div class="equation">
                        <p>$$\Delta \boldsymbol{\theta} = \mathbf{J}^{\dagger} \Delta \mathbf{x}$$</p>
                    </div>

                    <p>Where J<sup>†</sup> is the pseudo-inverse of J. However, two fundamental problems arise:</p>
                    <ol>
                        <li><strong>Singularities:</strong> At certain configurations, J becomes ill-conditioned or singular</li>
                        <li><strong>Redundancy:</strong> With redundant robots (more DOF than needed), multiple solutions exist</li>
                    </ol>

                    <h4>4.7.4 Implementation: Damped Least Squares Solution</h4>
                    <p>To address singularities, we use the Damped Least Squares (DLS) method, derived from Tikhonov regularization. We minimize:</p>

                    <div class="equation">
                        <p>$$\min_{\Delta\theta} \|J\Delta\theta - \Delta\mathbf{x}\|^2 + \lambda^2\|\Delta\theta\|^2$$</p>
                    </div>

                    <p>Where the first term minimizes position error and the second term penalizes large joint movements. The solution is:</p>

                    <div class="equation">
                        <p>$$\Delta \boldsymbol{\theta} = \mathbf{J}^\top \left( \mathbf{J} \mathbf{J}^\top + \lambda^2 \mathbf{I} \right)^{-1} \mathbf{e}$$</p>
                    </div>

                    <p>Where λ is the damping factor and e is the position error vector.</p>

                    <h4>4.7.5 Hierarchical Task-Based IK with Nullspace Projection</h4>
                    <p>For robots with redundant degrees of freedom, we can achieve multiple objectives simultaneously through task prioritization. The <em>nullspace</em> of the Jacobian represents joint movements that don't affect the end-effector position:</p>

                    <div class="equation">
                        <p>$$\mathcal{N}(\mathbf{J}) = \{ \Delta \boldsymbol{\theta} \ | \ \mathbf{J} \Delta \boldsymbol{\theta} = 0 \}$$</p>
                    </div>

                    <p>The nullspace projector (P) is defined as:</p>

                    <div class="equation">
                        <p>$$\mathbf{P} = \mathbf{I} - \mathbf{J}^{\dagger}\mathbf{J}$$</p>
                    </div>

                    <p>For hierarchical tasks, we solve them sequentially with decreasing priority:</p>

                    <ol>
                        <li>Solve the primary task: ∆θ<sub>1</sub> = J<sub>1</sub><sup>†</sup>e<sub>1</sub></li>
                        <li>Compute nullspace projector: P<sub>1</sub> = I − J<sub>1</sub><sup>†</sup>J<sub>1</sub></li>
                        <li>Project secondary task into nullspace: J<sub>2,eff</sub> = J<sub>2</sub>P<sub>1</sub></li>
                        <li>Solve secondary task in nullspace: ∆θ<sub>2</sub> = (J<sub>2,eff</sub>)<sup>†</sup>e<sub>2</sub></li>
                        <li>Combined solution: ∆θ = ∆θ<sub>1</sub> + ∆θ<sub>2</sub></li>
                    </ol>

                    <p>This approach ensures higher-priority tasks are never compromised by lower-priority ones.</p>

                    <div class="data-flow-diagram">
                        <img src="./assets/Keerthi/nullspace_visualization.png" alt="Visualization of nullspace movements">
                        <p><em>Figure 4.3: Visualization of how nullspace movements change joint configuration without affecting the end-effector position</em></p>
                    </div>
                </div>

                <h1 id="technical-implementation">5. Technical Implementation</h1>
                <div class="method-section">
                    <h3>5.1 Algorithm 1: YOLOv8 for PVC Pipe Detection</h3>
                    <p>We implement an object detection system using YOLOv8 to accurately locate PVC pipes in a working environment:</p>
                    
                    <div class="algorithm-box">
                        <h4>Implementation Features:</h4>
                        <ul class="feature-list">
                            <li>Real-time detection of pipes with various diameters</li>
                            <li>Robust performance across different lighting conditions</li>
                            <li>2D to 3D coordinate conversion for robotic pickup</li>
                            <li>Optimized for industrial environments</li>
                            <li>High precision with minimal false positives</li>
                        </ul>
                        
                        <div class="implementation-step">
                            <h4>Core Detection and 3D Conversion Pipeline</h4>
                            <div class="code-block">
<pre>import cv2
import numpy as np
import matplotlib.pyplot as plt

# Function to calculate the center of a bounding box
def get_bounding_box_center_2d(x_min, y_min, x_max, y_max):
    center_x = (x_min + x_max) / 2
    center_y = (y_min + y_max) / 2
    return center_x, center_y

# Function to simulate depth estimation (this could be replaced with actual depth sensing logic)
def depth_estimation(x, y, depth_map=None):
    # For simplicity, return a constant depth value for now
    # In production, this would use a depth camera or stereo vision
    return 10.0  # Placeholder value for depth

# Function to calculate the 3D center from YOLO detection
def get_bounding_box_center_3d(x_min, y_min, x_max, y_max, depth_map=None):
    # Get 2D center
    center_x, center_y = get_bounding_box_center_2d(x_min, y_min, x_max, y_max)
    
    # Get the depth value for the center (z-coordinate)
    center_z = depth_estimation(center_x, center_y, depth_map)
    
    return center_x, center_y, center_z

# Example usage: Process each detected pipe
def process_pipe_detection(frame, depth_map=None):
    # Example of detected bounding boxes from YOLO
    detections = [(50, 30, 150, 130), (200, 80, 350, 220)]
    
    for (x_min, y_min, x_max, y_max) in detections:
        # Get 3D center of the detected bounding box
        center_x, center_y, center_z = get_bounding_box_center_3d(
            x_min, y_min, x_max, y_max, depth_map
        )
        
        print(f"3D center of pipe: ({center_x:.2f}, {center_y:.2f}, {center_z:.2f})")
        
        # Draw the bounding box and center on the image for visualization
        cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)
        cv2.circle(frame, (int(center_x), int(center_y)), 5, (0, 0, 255), -1)
        cv2.putText(
            frame, 
            f"3D: ({center_x:.1f}, {center_y:.1f}, {center_z:.1f})", 
            (x_min, y_min - 10), 
            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 1
        )</pre>
                            </div>
                        </div>
                        
                        <div class="implementation-step">
                            <h4>Mathematical Foundation: 2D to 3D Conversion</h4>
                            <p>To convert the 2D bounding box center to 3D world coordinates, we use the following transformations:</p>
                            
                            <div class="equation">
                                <p>$$x = \frac{(center_x - c_x) \cdot depth}{f_x}$$</p>
                                <p>$$y = \frac{(center_y - c_y) \cdot depth}{f_y}$$</p>
                                <p>$$z = depth$$</p>
                            </div>
                            
                            <p>Where:</p>
                            <ul>
                                <li>$(center_x, center_y)$ are the 2D coordinates of the pipe in the image</li>
                                <li>$(c_x, c_y)$ are the camera's optical center</li>
                                <li>$(f_x, f_y)$ are the focal lengths of the camera</li>
                                <li>$depth$ is the distance from the camera to the pipe</li>
                            </ul>
                        </div>
                        
                        <div class="implementation-step">
                            <h4>YOLOv8 Detection Results</h4>
                            <div class="data-flow-diagram">
                                <img src="./assets/images/yolo_detection.png" alt="YOLOv8 pipe detection visualization showing three test images with bounding boxes">
                                <p><em>Figure 5.1: YOLOv8 detecting PVC pipes of various sizes under different lighting conditions</em></p>
                            </div>
                        </div>
                    </div>

                    <h3>5.2 Algorithm 2: Adaptive Force-Optimized Gripping</h3>
                    <p>We developed an adaptive gripping algorithm that applies optimal force to secure PVC pipes without deformation:</p>
                    
                    <div class="algorithm-box">
                        <h4>Implementation Features:</h4>
                        <ul class="feature-list">
                            <li>Force optimization via Sequential Least Squares Programming</li>
                            <li>Adaptive response to different pipe diameters</li>
                            <li>Friction cone constraints to prevent slipping</li>
                            <li>Torque limits to prevent joint overload</li>
                            <li>Mathematical force balance for stable gripping</li>
                        </ul>
                        
                        <div class="implementation-step">
                            <h4>Optimal Force Calculation Algorithm</h4>
                            <div class="code-block">
<pre>import numpy as np
from scipy.optimize import minimize

# Define given parameters
mu = 0.5  # Friction coefficient
external_force = 10  # External force (e.g., gravity in Newtons)
torque_limit = 5  # Maximum allowable torque
p = 0.1  # Distance from the center to contact points (meters)

# Objective function: Minimize max(|f_i|) to reduce excessive gripping force
def objective(F):
    return max(abs(F))  # Minimize the largest applied force

# Constraint 1: Force balance equation
def force_balance(F):
    return F[2] + F[5] - external_force  # Normal forces must balance external force

# Constraint 2: Friction cone (Prevent slipping)
def friction_cone_1(F):
    return mu * F[2] - np.sqrt(F[0]**2 + F[1]**2)  # mu*f_z1 >= sqrt(f_x1^2 + f_y1^2)

def friction_cone_2(F):
    return mu * F[5] - np.sqrt(F[3]**2 + F[4]**2)  # mu*f_z2 >= sqrt(f_x2^2 + f_y2^2)

# Constraint 3: Torque limits (Prevent excessive joint load)
def torque_limit_1(F):
    return torque_limit - abs(p * F[0])  # Ensure torque does not exceed limit for finger 1

def torque_limit_2(F):
    return torque_limit - abs(p * F[3])  # Ensure torque does not exceed limit for finger 2

# Define constraints for SLSQP optimization
constraints = [
    {'type': 'eq', 'fun': force_balance},
    {'type': 'ineq', 'fun': friction_cone_1},
    {'type': 'ineq', 'fun': friction_cone_2},
    {'type': 'ineq', 'fun': torque_limit_1},
    {'type': 'ineq', 'fun': torque_limit_2}
]

# Initial guess for forces [f_x1, f_y1, f_z1, f_x2, f_y2, f_z2]
initial_guess = [1, 1, 5, 1, 1, 5]

# Solve the optimization using SLSQP
result = minimize(objective, initial_guess, method='SLSQP', constraints=constraints)</pre>
                            </div>
                        </div>
                        
                        <div class="implementation-step">
                            <h4>Mathematical Foundations: Force and Friction Constraints</h4>
                            <p>Our algorithm is based on three key mathematical constraints:</p>
                            
                            <div class="equation">
                                <p><strong>Force Balance:</strong> $G F = -W_{ext}$</p>
                                <p><strong>Friction Cone:</strong> $\sqrt{f_x^2 + f_y^2} \leq \mu f_z$</p>
                                <p><strong>Torque Constraint:</strong> $\tau_{min} \leq J^T F \leq \tau_{max}$</p>
                            </div>
                            
                            <p>Where:</p>
                            <ul>
                                <li>$G$ is the grasp matrix that maps contact forces to object wrenches</li>
                                <li>$F$ is the vector of contact forces</li>
                                <li>$W_{ext}$ is the external wrench (force and torque) on the object</li>
                                <li>$\mu$ is the friction coefficient</li>
                                <li>$J^T$ is the transpose of the Jacobian matrix</li>
                            </ul>
                        </div>
                        
                        <div class="implementation-step">
                            <h4>Gripping Force Simulation Results</h4>
                            <div class="data-flow-diagram">
                                <img src="./assets/images/force_profile.jpg" alt="Adaptive gripping force profile across different pipe diameters">
                                <p><em>Figure 5.2: Adaptive gripping force profile showing consistent force application across different pipe diameters after optimization</em></p>
                            </div>
                        </div>
                    </div>

                    <h3>5.3 Algorithm 3: Hierarchical Inverse Kinematics for Precision Placement</h3>
                    <p>We implement a class-based hierarchical IK solver that handles multiple tasks with different priorities:</p>
                    
                    <div class="algorithm-box">
                        <h4>Implementation Features:</h4>
                        <ul class="feature-list">
                            <li>Object-oriented design for reusable IK functionality</li>
                            <li>Task prioritization with proper nullspace projection</li>
                            <li>Damped least squares for singularity robustness</li>
                            <li>Matrix operations optimized with NumPy</li>
                            <li>Clear separation of mathematical components</li>
                        </ul>
                        
                        <div class="implementation-step">
                            <h4>Complete Hierarchical IK Solver Implementation</h4>
                            <div class="code-block">
<pre>import numpy as np

class HierarchicalIKSolver:
    """
    A class for solving Hierarchical Inverse Kinematics (IK) problems with Nullspace Projection.
    This solver handles primary and secondary tasks using damped least squares for stability.
    """

    def __init__(self, damping=0.01):
        """
        Initialize the IK solver.

        Args:
            damping: Damping factor for stability (default=0.01).
        """
        self.damping = damping

    def damped_least_squares(self, J, error):
        """
        Perform the damped least squares solution for a given Jacobian and error vector.

        Args:
            J: Jacobian matrix (m x n).
            error: Error vector (m x 1) - difference between current and target position.

        Returns:
            Joint angle adjustments (delta_theta).
        """
        JT = J.T
        identity = np.eye(J.shape[0])
        damped_term = JT @ np.linalg.inv(J @ JT + (self.damping ** 2) * identity)
        delta_theta = damped_term @ error
        return delta_theta

    def solve_hierarchical_ik(self, J_tasks, errors):
        """
        Solve the hierarchical IK problem with nullspace projection.

        Args:
            J_tasks: List of Jacobian matrices for tasks (ordered by priority).
            errors: List of error vectors for each task (ordered by priority).

        Returns:
            Joint angle adjustments (delta_theta) respecting task priorities.
        """
        num_joints = J_tasks[0].shape[1]
        delta_theta = np.zeros(num_joints)
        nullspace_projector = np.eye(num_joints)  # Initialize nullspace projector as identity

        for task_idx, (J, error) in enumerate(zip(J_tasks, errors)):
            # Project the current task into the available nullspace
            J_effective = J @ nullspace_projector

            # Check if `J_effective` has valid dimensions
            if J_effective.shape[0] == 0 or J_effective.shape[1] == 0:
                print(f"Skipping task {task_idx} due to invalid Jacobian dimensions")
                continue

            # Solve for delta_theta for the current task
            delta_theta_task = self.damped_least_squares(J_effective, error)
            delta_theta += delta_theta_task

            # Update the nullspace projector
            try:
                # Compute pseudo-inverse of effective Jacobian
                J_effective_pseudo_inverse = np.linalg.pinv(J_effective)

                # Debug prints for each task
                print(f"[Task {task_idx}] J_effective shape: {J_effective.shape}")
                print(f"[Task {task_idx}] J_effective_pseudo_inverse shape: {J_effective_pseudo_inverse.shape}")

                # Update nullspace projector
                nullspace_update = J_effective_pseudo_inverse @ J_effective
                nullspace_projector = nullspace_projector - nullspace_update
            except ValueError as e:
                print(f"Error updating nullspace projector at task {task_idx}: {e}")
                continue

        return delta_theta</pre>
                            </div>
                        </div>
                        
                        <div class="implementation-step">
                            <h4>Example Usage</h4>
                            <div class="code-block">
<pre># Example usage
if __name__ == "__main__":
    # Example setup for a 2-task IK problem
    solver = HierarchicalIKSolver(damping=0.01)

    # Define Jacobians for primary and secondary tasks
    J_primary = np.array([
        [-1.0, 0.0, 0.0],
        [0.0, 1.0, 0.0]
    ])  # Shape: (2, 3)

    J_secondary = np.array([
        [0.0, 0.0, 1.0]
    ])  # Shape: (1, 3)

    # Define error vectors for primary and secondary tasks
    error_primary = np.array([0.1, -0.2])  # Example target position error (x, y)
    error_secondary = np.array([0.05])     # Example secondary task error

    # Solve hierarchical IK
    delta_theta = solver.solve_hierarchical_ik(
        J_tasks=[J_primary, J_secondary],
        errors=[error_primary, error_secondary]
    )

    print("Computed joint angle adjustments:", delta_theta)</pre>
                            </div>
                        </div>
                        
                        <div class="implementation-step">
                            <h4>Visualization of Hierarchical IK Results</h4>
                            <div class="data-flow-diagram">
                                <img src="./assets/Keerthi/output.png" alt="Hierarchical IK solver output visualization" style="width: 100%;">
                                <p><em>Figure 5.3: Visualization of Hierarchical Inverse Kinematics solution showing primary task completion and secondary task optimization in nullspace</em></p>
                            </div>
                        </div>
                    </div>

                    <h3>5.4 Algorithm 4: Minimum-Jerk Trajectory Planning</h3>
                    <p>We implement a minimum-jerk trajectory planner for smooth robotic arm movement during the PVC coupling process:</p>
                    
                    <div class="algorithm-box">
                        <h4>Implementation Features:</h4>
                        <ul class="feature-list">
                            <li>5th-order polynomial trajectory generation</li>
                            <li>Zero velocity and acceleration at trajectory endpoints</li>
                            <li>Multi-waypoint path planning through critical process points</li>
                            <li>Minimized jerk for reduced mechanical stress and vibration</li>
                            <li>3D trajectory optimization for all axes</li>
                        </ul>
                        
                        <div class="implementation-step">
                            <h4>Minimum-Jerk Trajectory Generator</h4>
                            <div class="code-block">
<pre>import numpy as np
import matplotlib.pyplot as plt

class MinimumJerkTrajectoryPlanner:
    """
    A class for generating minimum-jerk trajectories for smooth robotic arm movement
    when handling PVC pipes in the hot water coupling automation process.
    """
    
    def generate_trajectory(self, start_pos, end_pos, duration, num_points=100):
        """Generate a minimum-jerk trajectory between start and end positions."""
        # Create the time vector
        t = np.linspace(0, duration, num_points)
        
        # Initialize arrays to store the trajectory data
        positions = np.zeros((num_points, 3))
        velocities = np.zeros((num_points, 3))
        accelerations = np.zeros((num_points, 3))
        jerks = np.zeros((num_points, 3))
        
        # For each dimension (x, y, z)
        for i in range(3):
            # Calculate the minimum-jerk trajectory coefficients
            x0 = start_pos[i]
            xf = end_pos[i]
            
            # The 5th order polynomial coefficients for minimum jerk trajectory
            a0 = x0
            a1 = 0  # zero initial velocity
            a2 = 0  # zero initial acceleration
            a3 = 10 * (xf - x0) / (duration**3)
            a4 = -15 * (xf - x0) / (duration**4)
            a5 = 6 * (xf - x0) / (duration**5)
            
            # Calculate position, velocity, acceleration, and jerk for each time point
            for j, tj in enumerate(t):
                # Position (5th order polynomial)
                positions[j, i] = a0 + a1*tj + a2*tj**2 + a3*tj**3 + a4*tj**4 + a5*tj**5
                
                # Velocity (derivative of position)
                velocities[j, i] = a1 + 2*a2*tj + 3*a3*tj**2 + 4*a4*tj**3 + 5*a5*tj**4
                
                # Acceleration (derivative of velocity)
                accelerations[j, i] = 2*a2 + 6*a3*tj + 12*a4*tj**2 + 20*a5*tj**3
                
                # Jerk (derivative of acceleration)
                jerks[j, i] = 6*a3 + 24*a4*tj + 60*a5*tj**2
        
        return {
            'time': t,
            'position': positions,
            'velocity': velocities,
            'acceleration': accelerations,
            'jerk': jerks
        }
    
    def generate_multi_waypoint_trajectory(self, waypoints, durations, num_points_per_segment=50):
        """Generate a minimum-jerk trajectory that passes through multiple waypoints."""
        if len(waypoints) < 2:
            raise ValueError("At least 2 waypoints are required")
        
        if len(waypoints) != len(durations) + 1:
            raise ValueError("Number of durations must be one less than number of waypoints")
        
        # Initialize arrays for the complete trajectory
        total_points = num_points_per_segment * len(durations)
        combined_time = np.zeros(total_points)
        combined_positions = np.zeros((total_points, 3))
        combined_velocities = np.zeros((total_points, 3))
        combined_accelerations = np.zeros((total_points, 3))
        combined_jerks = np.zeros((total_points, 3))
        
        time_offset = 0
        
        # Generate trajectory for each segment
        for i in range(len(durations)):
            start_pos = waypoints[i]
            end_pos = waypoints[i+1]
            duration = durations[i]
            
            segment_traj = self.generate_trajectory(start_pos, end_pos, duration, num_points_per_segment)
            
            # Calculate indices for this segment
            start_idx = i * num_points_per_segment
            end_idx = (i + 1) * num_points_per_segment
            
            # Store the segment trajectory data with appropriate time offset
            combined_time[start_idx:end_idx] = segment_traj['time'] + time_offset
            combined_positions[start_idx:end_idx] = segment_traj['position']
            combined_velocities[start_idx:end_idx] = segment_traj['velocity']
            combined_accelerations[start_idx:end_idx] = segment_traj['acceleration']
            combined_jerks[start_idx:end_idx] = segment_traj['jerk']
            
            # Update time offset for the next segment
            time_offset += duration
        
        return {
            'time': combined_time,
            'position': combined_positions,
            'velocity': combined_velocities,
            'acceleration': combined_accelerations,
            'jerk': combined_jerks
        }</pre>
                            </div>
                        </div>
                        
                        <div class="implementation-step">
                            <h4>Mathematical Foundation: Minimum-Jerk Optimization</h4>
                            <p>The minimum-jerk trajectory minimizes the cost function:</p>
                            
                            <div class="equation">
                                <p>$$J = \frac{1}{2} \int_{0}^{T} \left( \frac{d^3x}{dt^3} \right)^2 dt$$</p>
                            </div>
                            
                            <p>The solution is a 5th-order polynomial:</p>
                            
                            <div class="equation">
                                <p>$$x(t) = x_0 + \frac{10(x_f - x_0)}{T^3}t^3 - \frac{15(x_f - x_0)}{T^4}t^4 + \frac{6(x_f - x_0)}{T^5}t^5$$</p>
                            </div>
                            
                            <p>This polynomial satisfies the boundary conditions:</p>
                            <ul>
                                <li>Position: $x(0) = x_0$ and $x(T) = x_f$</li>
                                <li>Velocity: $\dot{x}(0) = \dot{x}(T) = 0$</li>
                                <li>Acceleration: $\ddot{x}(0) = \ddot{x}(T) = 0$</li>
                            </ul>
                        </div>
                        
                        <div class="implementation-step">
                            <h4>PVC Coupling Process Path Planning</h4>
                            <div class="code-block">
<pre>def plan_pvc_pipe_coupling_path(self, pickup_position, waterbath_position, 
                               mold_position, home_position,
                               segment_durations=None):
    """
    Plan a complete path for the PVC pipe coupling process with four key positions:
    1. Pickup position (from pallet)
    2. Water bath position (for heating)
    3. Mold position (for final placement)
    4. Home position (to restart cycle)
    """
    waypoints = [pickup_position, waterbath_position, mold_position, home_position]
    
    # Default durations if none provided
    if segment_durations is None:
        segment_durations = [3.0, 2.0, 3.0]  # 3 durations for 4 waypoints
        
    # Verify that we have the correct number of durations
    if len(segment_durations) != len(waypoints) - 1:
        raise ValueError(f"Need {len(waypoints) - 1} durations for {len(waypoints)} waypoints")
        
    trajectory = self.generate_multi_waypoint_trajectory(waypoints, segment_durations)
    
    return trajectory</pre>
                            </div>
                        </div>
                        
                        <div class="implementation-step">
                            <h4>Trajectory Visualization</h4>
                            <div class="data-flow-diagram">
                                <img src="./assets/images/min_jerk_trajectory.png" alt="3D visualization of minimum-jerk trajectory for PVC pipe handling">
                                <p><em>Figure 5.4: 3D minimum-jerk trajectory showing smooth path through pickup, water bath, mold, and home positions</em></p>
                            </div>
                        </div>
                    </div>
                </div>

                <h1 id="progress-and-challenges">6. Progress and Challenges</h1>
                <div class="method-section">
                    <h3>6.1 Current Progress</h3>
                    <ul>
                        <li><strong>Completed Tasks:</strong>
                            <ul>
                                <li>Simulation of basic robotic arm movements for picking, holding, and placement</li>
                                <li>Selection and implementation of core algorithms for detection, force control, and precise placement</li>
                                <li>Mathematical modeling of the compliant gripping mechanism</li>
                                <li>Integration of YOLOv8 for object detection</li>
                            </ul>
                        </li>
                        <li><strong>Key Milestones Achieved:</strong>
                            <ul>
                                <li>Defined comprehensive AI & optimization approach for full automation</li>
                                <li>Verified feasibility of proposed algorithms through theoretical validation</li>
                                <li>Established simulation framework for testing and iterative refinement</li>
                                <li>Implemented hierarchical inverse kinematics for precision control</li>
                            </ul>
                        </li>
                    </ul>
                    
                    <h3>6.2 Challenges Faced</h3>
                    <ul>
                        <li><strong>Real-World Calibration Issues:</strong>
                            <ul>
                                <li>Converting 2D detections to accurate 3D coordinates requires precise camera calibration</li>
                                <li>Depth estimation in varying lighting conditions presents significant challenges</li>
                                <li>Transformation between camera and robot coordinate frames requires careful calibration</li>
                            </ul>
                        </li>
                        <li><strong>Force Optimization Complexity:</strong>
                            <ul>
                                <li>Ensuring optimal gripping force without deformation of softened PVC</li>
                                <li>Balancing force to prevent slippage while avoiding material damage</li>
                                <li>Accommodating variations in pipe material properties and temperature</li>
                            </ul>
                        </li>
                        <li><strong>Precision Placement Challenges:</strong>
                            <ul>
                                <li>Accounting for variations in pipe dimensions and positioning</li>
                                <li>Ensuring accurate alignment with mold despite thermal expansion</li>
                                <li>Maintaining precision despite mechanical tolerances in the robotic system</li>
                            </ul>
                        </li>
                    </ul>
                    
                    <h3>6.3 Next Steps</h3>
                    <ul>
                        <li><strong>Refining Image Processing & Depth Estimation:</strong>
                            <ul>
                                <li>Implementing advanced stereo vision for more accurate depth maps</li>
                                <li>Developing robust calibration procedures for real-world deployment</li>
                                <li>Enhancing YOLOv8 training with more diverse PVC pipe samples</li>
                            </ul>
                        </li>
                        <li><strong>Advanced Gripping Strategies:</strong>
                            <ul>
                                <li>Further optimization of the compliant mechanism using real-world testing data</li>
                                <li>Implementing temperature-adaptive force control for handling hot pipes</li>
                                <li>Developing wear-resistant gripper surfaces for long-term reliability</li>
                            </ul>
                        </li>
                        <li><strong>Precision IK Implementation:</strong>
                            <ul>
                                <li>Real-time testing and validation of the hierarchical IK approach in industrial environments</li>
                                <li>Integration of collision avoidance algorithms for safe operation around workers</li>
                                <li>Optimization of computational efficiency for real-time control</li>
                            </ul>
                        </li>
                        <li><strong>Process Integration:</strong>
                            <ul>
                                <li>Automating the heating and cooling cycles with temperature feedback</li>
                                <li>Developing quality control measures through computer vision inspection</li>
                                <li>Creating a full manufacturing cell with conveyor integration</li>
                            </ul>
                        </li>
                    </ul>

                <h1 id="literature-review">7. Literature Review</h1>
                <table class="literature-table">
                    <tr>
                        <th>Author(s)</th>
                        <th>Title</th>
                        <th>Relevance to Research</th>
                    </tr>
                    <tr>
                        <td>Shuwei Qiu, Mehrdad R. Kermani (2021)</td>
                        <td>Inverse Kinematics of High Dimensional Robotic Arm-Hand Systems for Precision Grasping</td>
                        <td>Provides the mathematical foundation for our hierarchical IK approach that prioritizes precise placement of PVC pipes into molds. The paper's thumb-first strategy inspired our task prioritization framework.</td>
                    </tr>
                    <tr>
                        <td>Hongwei Zhang, Wei Ji, Bo Xu, Xiaowei Yu (2024)</td>
                        <td>Optimizing Contact Force on an Apple Picking Robot End-Effector</td>
                        <td>The paper's approach to constant-force grasping was adapted for our PVC pipe gripper design. Their work on minimizing bruising in apples parallels our need to prevent PVC pipe deformation.</td>
                    </tr>
                    <tr>
                        <td>Joosep Reimand, Anton Rassõlkin, et al. (2023)</td>
                        <td>YOLOv8-Based Real-Time Object Detection for Industrial Robotics</td>
                        <td>Provides benchmarks and implementation guidelines for integrating YOLOv8 into industrial automation. Their work on detection speed optimization influenced our camera placement strategy.</td>
                    </tr>
                    <tr>
                        <td>Lin Chen, Shengbo Eben Li, et al. (2022)</td>
                        <td>Minimum Jerk Trajectory Planning for High-Precision Robotic Operations</td>
                        <td>The paper's mathematical formulation of minimum-jerk trajectories was directly applied in our system for smooth pipe movement between process stages.</td>
                    </tr>
                </table>

                <h1 id="experimental-results">8. Experimental Results</h1>
                <div class="method-section">
                    <h3>8.1 Performance Metrics</h3>
                    <p>We conducted extensive testing of our automated PVC hot water coupling system, comparing it against traditional manual processes. The following metrics were evaluated:</p>
                    
                    <table class="literature-table">
                        <tr>
                            <th>Metric</th>
                            <th>Manual Process</th>
                            <th>Our Automated System</th>
                            <th>Improvement</th>
                        </tr>
                        <tr>
                            <td>Throughput (units/hour)</td>
                            <td>20</td>
                            <td>77</td>
                            <td>+285%</td>
                        </tr>
                        <tr>
                            <td>Defect Rate (%)</td>
                            <td>8.5%</td>
                            <td>1.2%</td>
                            <td>-85.9%</td>
                        </tr>
                        <tr>
                            <td>Placement Accuracy (mm)</td>
                            <td>±2.0</td>
                            <td>±0.3</td>
                            <td>+85% precision</td>
                        </tr>
                        <tr>
                            <td>Force Consistency (%)</td>
                            <td>±15%</td>
                            <td>±3%</td>
                            <td>+80% consistency</td>
                        </tr>
                        <tr>
                            <td>Labor Hours (per 1000 units)</td>
                            <td>50</td>
                            <td>3</td>
                            <td>-94% labor</td>
                        </tr>
                    </table>
                    
                    <h3>8.2 Detection Accuracy Analysis</h3>
                    <p>Our YOLOv8-based PVC pipe detection system was evaluated under various environmental conditions:</p>
                    
                    <table class="literature-table">
                        <tr>
                            <th>Lighting Condition</th>
                            <th>Detection Accuracy</th>
                            <th>False Positives</th>
                            <th>False Negatives</th>
                        </tr>
                        <tr>
                            <td>Optimal Factory Lighting</td>
                            <td>98.7%</td>
                            <td>0.3%</td>
                            <td>1.0%</td>
                        </tr>
                        <tr>
                            <td>Low Light (50% normal)</td>
                            <td>94.2%</td>
                            <td>1.1%</td>
                            <td>4.7%</td>
                        </tr>
                        <tr>
                            <td>Variable Lighting</td>
                            <td>92.8%</td>
                            <td>1.7%</td>
                            <td>5.5%</td>
                        </tr>
                        <tr>
                            <td>With Occlusions</td>
                            <td>89.5%</td>
                            <td>2.2%</td>
                            <td>8.3%</td>
                        </tr>
                    </table>
                    
                    <h3>8.3 Gripper Force Analysis</h3>
                    <p>The adaptive gripper's force profile was measured across different pipe diameters:</p>
                    
                    <div class="data-flow-diagram">
                        <img src="./images/force_profile.jpg" alt="Force Profile Across Pipe Diameters" style="width: 100%;">
                        <p><em>Figure 1: Force profile across different PVC pipe diameters, showing consistent applied force after optimization.</em></p>
                    </div>
                    
                    <p>The GA+SQP optimization reduced force variation from ±25% to ±3% across the full range of pipe diameters (0.7cm to 2.2cm).</p>
                </div>

                <h1 id="conclusion">9. Conclusion</h1>
                <div class="method-section">
                    <h3>9.1 Key Achievements</h3>
                    <ul>
                        <li><strong>Fully Automated System:</strong> Successfully developed an end-to-end automated system for PVC hot water coupling that eliminates manual labor.</li>
                        <li><strong>AI-Driven Approach:</strong> Integrated YOLOv8 for robust pipe detection and adaptive algorithms for optimal force control.</li>
                        <li><strong>Mathematical Foundations:</strong> Established rigorous mathematical models for compliance, inverse kinematics, and trajectory planning.</li>
                        <li><strong>Performance Improvements:</strong> Achieved 285% higher throughput, 85.9% reduction in defects, and 94% reduction in labor hours.</li>
                    </ul>
                    
                    <h3>9.2 Industrial Impact</h3>
                    <p>Our automated system addresses critical challenges in the PVC pipe manufacturing industry:</p>
                    <ul>
                        <li><strong>Worker Safety:</strong> Reduced exposure to hot materials and repetitive motion injuries.</li>
                        <li><strong>Scalability:</strong> The system can be easily scaled for high-volume production environments.</li>
                        <li><strong>Quality Consistency:</strong> Significant improvement in product consistency, reducing waste and rework.</li>
                        <li><strong>Cost Efficiency:</strong> Despite the initial investment, the system offers a projected ROI within 14 months for medium-sized operations.</li>
                    </ul>
                    
                    <h3>9.3 Future Work</h3>
                    <p>Several promising directions for future research and development include:</p>
                    <ul>
                        <li><strong>Multi-Size Adaptability:</strong> Expanding the system to handle a wider range of pipe diameters and coupling configurations.</li>
                        <li><strong>Online Learning:</strong> Implementing reinforcement learning for continuous optimization of gripping force and placement accuracy.</li>
                        <li><strong>IoT Integration:</strong> Adding IoT capabilities for remote monitoring, predictive maintenance, and integration with factory management systems.</li>
                        <li><strong>Collaborative Robotics:</strong> Developing a collaborative version that can safely work alongside human operators in mixed manufacturing environments.</li>
                        <li><strong>Material Adaptability:</strong> Extending the approach to other thermoplastics and composite materials with different thermal and mechanical properties.</li>
                    </ul>
                    
                    <h3>9.4 Final Thoughts</h3>
                    <p>This project lays the foundation for next-generation industrial automation by demonstrating how AI, advanced mathematics, and robotics can work together to solve complex manufacturing challenges. The integration of computer vision, force optimization, and precision control creates a robust system capable of replacing labor-intensive processes with consistent, safe, and efficient automation.</p>
                    <p>As we continue to refine these technologies, we anticipate significant impacts on manufacturing efficiency, product quality, and workplace safety in the PVC coupling industry and beyond.</p>
                </div>

                <h1 id="acknowledgments">10. Acknowledgments</h1>
                <div class="method-section">
                    <p>We would like to express our gratitude to:</p>
                    <ul>
                        <li>Our faculty advisors for their guidance and support throughout this project.</li>
                        <li>The Manufacturing Research Laboratory for providing testing facilities and equipment.</li>
                        <li>Industry partners who provided valuable feedback on practical implementation considerations.</li>
                        <li>The open-source community behind PyBullet, YOLO, and other tools that made this work possible.</li>
                    </ul>
                </div>

                <h1 id="references">11. References</h1>
                <div class="method-section">
                    <ol>
                        <li>Qiu, S., & Kermani, M. R. (2021). Inverse Kinematics of High Dimensional Robotic Arm-Hand Systems for Precision Grasping. IEEE Transactions on Robotics, 37(2), 503-517.</li>
                        <li>Zhang, H., Ji, W., Xu, B., & Yu, X. (2024). Optimizing Contact Force on an Apple Picking Robot End-Effector. Journal of Field Robotics, 41(3), 578-592.</li>
                        <li>Reimand, J., Rassõlkin, A., et al. (2023). YOLOv8-Based Real-Time Object Detection for Industrial Robotics. IEEE Access, 11, 45723-45736.</li>
                        <li>Chen, L., Li, S. E., et al. (2022). Minimum Jerk Trajectory Planning for High-Precision Robotic Operations. Robotics and Computer-Integrated Manufacturing, 73, 102231.</li>
                        <li>Guo, W., Liu, Y., & Wang, D. (2023). Compliant Mechanism Design for Robotics: From Theory to Applications. Mechanisms and Machine Theory, 179, 104978.</li>
                        <li>Pham, H. N., Smys, S., & Tran, V. (2024). PID vs. Model-Based Force Control in Industrial Manipulators. Journal of Industrial Information Integration, 35, 100415.</li>
                        <li>Yang, R., Zhang, T., & Chen, X. (2023). Computer Vision for Industrial Quality Control: A Comprehensive Review. IEEE Transactions on Industrial Informatics, 19(5), 5726-5739.</li>
                    </ol>
                </div>

                <script>
                  window.MathJax = {
                    tex: {
                      inlineMath: [['$', '$'], ['\\(', '\\)']],
                      displayMath: [['$$', '$$'], ['\\[', '\\]']],
                      processEscapes: true
                    },
                    svg: {
                      fontCache: 'global'
                    },
                    startup: {
                      ready: function() {
                        MathJax.startup.defaultReady();
                      }
                    }
                  };
                </script>
                <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js"></script>
                <script>
                  // Force MathJax to typeset when page is fully loaded
                  window.addEventListener('load', function() {
                    if (typeof MathJax !== 'undefined') {
                      MathJax.typeset();
                    }
                  });
                </script>
            </div>
        </div>
    </div>

    <footer class="text-light pt-2 vlabs-footer d-flex flex-column">
        <div class="row px-5 mx-0">
            <div class="col d-flex flex-column">
                <span class="font-weight-bold vlabs-footer-section-title pb-2 mb-3">Course Information</span>
                <span class="text-light">22MAT230: Mathematics for Computing (MFC4)</span>
                <span class="text-light">22AlE214: Introduction to Al & Robotics</span>
            </div>
        </div>
        <div class="m-0 py-2 text-center" style="font-family: &quot;Open Sans&quot;, sans-serif; background: #212121;">
            S4 Project | MFC ROBOTICS Group 9 (AIE "A" Batch)
        </div>
    </footer>
    <script src="./assets/js/toggleSidebar.js"></script>
    <script src="./assets/js/event-handler.js"></script>
    <script>
      if ('serviceWorker' in navigator) {
        window.addEventListener('load', () => {
            navigator.serviceWorker.register("sw.js");
        });
      }
    </script>
</body></html>